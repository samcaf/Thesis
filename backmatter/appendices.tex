\setcounter{chapter}{1}
% ==============================================
\chapter*%[A Mathematical Primer]
{Appendix A: A Mathematical Primer}
% ==============================================
\addcontentsline{toc}{chapter}{\bf{Appendix A:~~A Mathematical Primer}}
\markboth{\bf{Appendix A: A Mathematical Primer}}{}

% ===========================================================
\section*{A.I\phantom{IIV.}Distributions}
% ===========================================================
\setcounter{section}{1}
\addcontentsline{toc}{section}{A.I\phantom{IIV.}Distributions}

A generalized function (distribution) is defined through its action on test functions rather than pointwise values. It is useful for describing singularities and sharp transitions in physical models.

\begin{definitionbox}{Distribution}{distribution}
    \emph{\Glspl{distribution}} generalize the concept of functions to accommodate objects, like delta functions or \glslink{plus-fn}{plus-functions}, that do not correspond to traditional functions but can still be useful in the description of physical phenomena -- especially phenomena involving singularities.
    %
    Distributions can be understood in terms of their behavior when integrated against a space of test functions.

    \vspace{7pt}
    \hrule
    \vspace{7pt}

    More formally, a distribution \( T \) is a continuous linear functional that maps a test function \( \varphi(x) \) to a real or complex number.
    %
    By the \href{https://en.wikipedia.org/wiki/Riesz%E2%80%93Markov%E2%80%93Kakutani_representation_theorem}{\vocab{Riesz–Markov–Kakutani representation theorem}}, linear functionals are related to Borel measures on the space on which the corresponding functions act.
    %
    Thus, we may unambiguously write
    \[
    T[\varphi] = \int_{-\infty}^{\infty} T(x) \varphi(x) \, \dd x
    \]
    where \( \varphi(x) \) is a smooth test function.
\end{definitionbox}

A familiar example of a generalized function is the Dirac delta function, defined by
\begin{align}
    \delta(x-a)[\phi] = \int \delta(x-a)\phi(x) \dd x = \phi(a)
    \,.
\end{align}
%
Another useful distribution is the \vocab{Cauchy Principle Value}, which we examine in \Prob{principle-value}.


% --------------------------------------------------------
% Plus-function
% --------------------------------------------------------
The main reason we discuss distributions here, however, is the prominent role played by \glslink{plus-fn}{plus-functions} in this thesis in providing a concrete and consistent mathematical description of the singular behavior of partonic splitting.

% -----------------------------------
% Definition Comment:
% -----------------------------------
\begin{definitionbox}{
% Definition Header:
Plus-Distribution
}{}
    A \vocab{plus-distribution} (or ``plus-function'', or ``plus-function regulated distribution'') is a modified version of a ``parent function'' which is often so singular that it cannot be integrated on its own.
    %
    Plus-distribution regularization (or ``plus regularization'') turns the parent function into an integrable distribution.

    \vspace{7pt}
    \hrule
    \vspace{7pt}

    % Definition Body:
    Let us consider the following ingredients:
    \begin{itemize}
        \item
            let \(f(x)\) denote a function on \(\RR\);
        \item
            let \(\mc R \subset \RR\) denote a one-dimensional region;

        \item
            let \(p \in \mc R\) denote a point around which we would like \(f(x)\) to be regularized -- in most cases, \(f(x)\) will have a simple pole or similar singularity near \(p\).
    \end{itemize}

    The \vocab{plus-distribution} \(\le[f(x)\ri]_{+,p}^{x \in \mc R}\) is defined through its action on test functions in the integration region \(\mc R\):
    \begin{equation}
        \int_{\mc R} \dd x\le[f(x)\ri]_{+,p}^{x \in \mc R} g(x) \eqdelta \int_{\mc R} \dd x f(x) \le(g(x) - g(p)\ri)
        ,
    \end{equation}
    where \(g(x)\) is a test function in the domain of integration \(\mc R\) which is regular at \(p\).
\end{definitionbox}

\remark{}{
    The notation above is a bit cumbersome and indeed, I have never seen it before.
    %
    In cases where it is clear what \(x\), \(\mc R\), and \(p\) should be, I will omit them.
    %
    However, I found this precise (if verbose) notation helpful in some of the following examples, especially those in which multiple variables are involved and may appear inside the plus-distribution.
}

\remark{}{
    \label{remark:extended_definition}
    The definition of the plus-distribution may be extended relative to the above definition, so that it may be integrated outside of the domain of integration \(\mc R\).
    %
    Formally, we may do this by writing
    \begin{equation}
        \label{eq:extended_plus-fn}
        \le[f(x)\ri]_{+,p}^{\mc R} =
        f(x)
        -
        \delta(x - p) \int_{\mc R} f(t) \dd t
        .
    \end{equation}
    %
    We will assume that \(f(x)\) is integrable away from \(p\).
}

\begin{exercise}
    \label{ex:plus-fn-dervivative}
    Using \Eq{extended_plus-fn}, show that
    \begin{align}
        \label{eq:plus-fn-derivative}
        \dv{a} \le[f(x)\ri]_{+,p}P^{(b,a)}
        =
        -
        \dv{a} \le[f(x)\ri]_{+,p}^{(a,c)}
        =
        \delta(x-p) f(a)
        \,.
    \end{align}
\end{exercise}


\begin{example}{}
    If we would like to integrate the plus-distribution over a region of integration \(\mc R'\) which does \textit{not} include \(p\), our extended definition yields the natural result
    \begin{equation}
        \int_{\mc R'} \dd x\le[f(x)\ri]_{+,p}^{\mc R} g(x)
        =
        \int_{\mc R'} \dd x f(x) g(x)
        .
    \end{equation}
    The plus-distribution behaves identically to its parent function away from \(p\).

    On the other hand, if we would like to integrate the plus-distribution over a region of integration \(\mc R''\) which \textit{does} include \(p\), this yields
    \begin{equation}
        \int_{\mc R''} \dd x{\le[f(x)\ri]}_{+,p}^{\mc R} g(x)
        =
        \int_{\mc R''} \dd x f(x) (g(x) - g(p))
        -
        g(p) \int_{\mc R - \mc R''} \dd x f(x)
        ,
    \end{equation}
    where \(\mc R - \mc R''\) indicates a set difference, or all points in \(\mc R\) which are not in \(\mc R''\).
    %
    As we will see, these subtleties becomes important in some cases of physical interest.
\end{example}

\begin{exercise}
    As an application of the above example, derive
    \begin{align}
        \le[f(x)\ri]_{+,p}^{x \in \mc R}
        &=
        \le[f(x)\ri]_{+,p}^{x \in \mc R''}
        -
        \delta(x - p) \int_{\mc R - \mc R''} \dd t f(t)
        ,
    \end{align}
    where \(p \in \mc R''\) and \(\mc R'' \subset \mc R\).
\end{exercise}


\remark{}{
    We need to be a bit more careful if the function we would like to regularize has worse than a simple pole at \(p\).
    %
    Functions like \(\ln(x)/x\) may be regularized with the plus prescription used above, but functions like \(1/x^2\) require a different prescription.
    %
    For example, for functions which behave like \(x^{-\lambda}\) with \(n < \Re\lambda < n + 1\) lying in a strip between the natural numbers \(n\) and \(n+1\) in the complex plane, we instead regularize via
    \begin{equation}
        \int_{\mc R} \dd x \le[\frac{1}{x^\lambda}\ri]_{+,p}^{\mc R} g(x)
        =
        \int_{\mc R} \frac{\dd x}{x^\lambda}
        \le(g(x) - g(p) - x g'(p) - \cdots - \frac{x^{n-1}}{(n-1)!}g^{(n-1)}(p)\ri)
        ,
    \end{equation}
    where we have assumed \(0 \in \mc R\) so that the singularity of \(x^\lambda\) indeed must be regularized.
    %
    The additional terms may also be organized formally via
    \begin{equation}
        \le[\frac{1}{x^\lambda}\ri]_{+,p}^{\mc R}
        =
        \frac{1}{x^\lambda}
        ~
        -
        ~
        \delta(x) \int_{\mc R} \frac{\dd t}{t^\lambda}
        ~
        +
        ~
        \delta'(x) \int_{\mc R} \frac{\dd t}{t^{\lambda-1}}
        ~
        + ~\cdots~ +
        ~
        (-1)^{n} \delta^{(n-1)}(x) \int_{\mc R} \frac{\dd t}{t^{\lambda-n}}
        .
    \end{equation}
    It is a fun exercise to show that integrating \(\le[1/x^2\ri]^{(0,1)}_{+,0}\) or \(\le[1/x^n\ri]^{(0,1)}_{+,0}\) against, say, simple polynomials requires additional terms of this type.
    %
    However, I personally have never seen situations which require this more detailed regularization of higher poles in physical applications.
}


Let us consider some simple examples involving integration of plus-distributions in one dimension.
%
Our goal is to understand some cases of physical interest, and we will develop our examples to be useful in the context of scattering and weighted observable correlators.
%
We use \(\le[1/(1-x)\ri]_+\) to denote \(\le[1/(1-x)\ri]^{(0,1)}_{+,1}\).

\begin{align}
    \int_{0}^{1} \dd x \le[\frac{1}{1-x}\ri]_+
    &=
    0
    ,
    \\
    \int_{0}^{1} \dd x \le[\frac{1}{1-x}\ri]_+ x
    &=
    \int_{0}^{1} \dd x \frac{x - 1}{1-x} = -1
    .
\end{align}

\remark{}{
    More generally, for any polynomial \(p(x)\), we may write \(p(x) - p(1) \eqdelta (1 - x) p_{(1)}(x)\);
    %
    here, \(p_{(1)}(x)\) is a polynomial, by the fundamental theorem of polynomials.
    %
    With these in hand, we may write
    \begin{equation}
        \int_{0}^{1} \dd x \le[\frac{1}{1-x}\ri]_+ p(x)
        =
        \int_{0}^{1} \dd x \frac{p(x) - p(1)}{1-x}
        =
        \int_{0}^{1} \dd x p_{(1)}(x)
        .
    \end{equation}
}
~\\
\begin{example}{}
    In the examples above, where our polynomial is especially simple and \(p(x) = x^n\), we have \(p_{(1)}(x) = -x^{n-1} - x^{n-2} - \cdots - 1\).
    %
    Therefore, in these simple cases, the plus-distribution integrals are simply harmonic numbers:
    \begin{align}
        \int_{0}^{1} \dd x \le[\frac{1}{1-x}\ri]_+ x^n
        =
        -\sum_{k=1}^n \frac{1}{k}
        =
        -H_n.
    \end{align}
\end{example}

One crucial piece of intuition that we can gain from these examples is that we should not trust our usual intuition when it comes to plus-distributions.
%
Though the integrands appear positive to an unsuspecting observer, the integrals are negative.
%
This is because the example test functions we considered are monotonically increasing.
%
In the case of \(\le[1/(1-x)\ri]_+\), this means that they are larger at the pole, and we subtract off values which are the maximum of the integrand.
%
Of course the results are negative!

I continue to distrust my intuition for plus-distributions, as we will see that they lead to even stranger results when we add more complicated and distributional behaviors to the integrand.


Let us consider slightly more complicated examples by changing the domain of integration relative to our previous examples.
\begin{align}
    \int_{a}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+
    &=
    \int_{a}^{1} \dd x\,\frac{1-1}{1-x} - \int_0^a \dd x \frac{1}{1-x}
    \\
    &=
    \log(1-a)
    \notag
    ,
    \\
    \int_{a}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ x
    &=
    \int_{a}^{1} \dd x\,\frac{x-1}{1-x} - \int_0^a \dd x \frac{1}{1-x}
    \\
    &=
    -(1 - a) + \log(1-a)
    \notag
    ,
    \\
    \int_{a}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ x^2
    &=
    \int_{a}^{1} \dd x\,\frac{x^2 - 1}{1-x} - \int_0^a \dd x \frac{1}{1-x}
    =
    -\int_a^1 \dd x\, (1+x) + \log(1-a)
    \\
    \notag
    &= -\frac{3}{2} + \frac{a^2}{2} + a + \log(1-a)
    .
\end{align}

More generally, it is simple to show:
~\\
\begin{example}{}
    The integral over incomplete bounds of a plus-distribution against \(x^n\) is
    \begin{align}
        \int_{a}^{1} \dd x\,\le[1/(1-x)\ri]_+ x^n
        =
        \sum_{k=1}^n a^k/k - H_n + \log(1-a).
    \end{align}
\end{example}

Finally, let us come to what I consider to be our first non-trivial example.
%
We will now study the interactions that occur when we have a delta-function and a plus-distribution in the same integral.
%
This type of behavior is important for deriving regularized fixed-order behavior of distributions of collider observables.
%
In \Prob{eec-dist}, we examine the example of the regularized behavior of the fixed-order \gls{eec}.
~\\
\begin{example}{}
    One of the simplest examples I have found for the interactions between plus-distributions and delta-functions is the following:
    \begin{align}
        \int_{0}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ \delta(b - x)
        &=
        \le[\frac{1}{1-b}\ri]_+
        ,
        ~~~~~~~~
        \text{where}~b \in [0,1].
    \end{align}

\vspace{7pt}
\hrule
\vspace{7pt}

\begin{proof}
It seems reasonable, by the usual rules of the delta function, that the result should be \([1/(1-b)]_+\) after we integrate over \(x\) to remove the delta-function.
%
To show this, let us prove it using the flavor of distributions:
%
we first integrate the above integral against a test function \(g(b)\), then integrate \([1/(1-b)]_+\) against the same test function, and see if we achieve the same result.

\begin{align}
    \int_0^1 \dd b \int_{0}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ \delta(b - x) g(b)
    &=
    \int_{0}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ \int_0^1 \dd b,\delta(b - x) g(b)
    \\
    \notag
    &=
    \int_{0}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ g(x)
    \\
    \notag
    &=
    \int_{0}^{1} \dd x\,\frac{g(x) - g(1)}{1-x}
    ,
    \\
    \int_0^1 \dd b \,\le[\frac{1}{1-b}\ri]_+ g(b) &= \int_0^1 \dd b\, \frac{g(b) - g(1)}{1-b}
    ,
\end{align}
and the results are equal.
%
However, we should check that this equality remains when we use our \textit{extended} definition of the plus-distribution, where the integration region is no longer from 0 to 1.
%
Let \(b_- < b_+ \in (0,1)\).
%
We now consider
\begin{align}
    \int_{b_-}^{b_+}\dd b\,
    \int_0^1 \dd x\,
    \le[\frac{1}{1-x}\ri]_+
    \delta(b - x) g(b)
    &=
    \int_{0}^1 \dd x\,
    \le[\frac{1}{1-x}\ri]_+
    \int_{b_-}^{b_+}\dd b\,
    \delta(b - x) g(b)
    \\
    &=
    \notag
    \int_0^1 \dd x\,
    \le[\frac{1}{1-x}\ri]_+ g(x) \Theta(b_- < x < b_+)
    \\
    &=
    \notag
    \int_{b_-}^{b_+} \dd x\, \frac{g(x)}{1-x}
    \\
    \int_{b_-}^{b_+}\dd b\,
    \le[\frac{1}{1-b}\ri]_+ g(b)
    &=
    \int_{b_-}^{b_+} \dd b\, \frac{g(b)}{1-b}
    .
\end{align}
These agree, and the derivation is identical if \(b_- = 0\).
%
The final check to perform, and the least trivial, involves
\begin{align}
    \int_{b_-}^{1} \dd b \,
    \int_{0}^1 \dd x\,
    \le[\frac{1}{1-x}\ri]_+
    \delta(b - x) g(b)
    &=
    \int_{0}^1 \dd x\,
    \le[\frac{1}{1-x}\ri]_+
    \int_{b_-}^{1} \dd b\,
    \delta(b - x) g(b)
    \\
    &=
    \notag
    \int_0^1 \dd x\,
    \le[\frac{1}{1-x}\ri]_+
    g(x) \Theta(b_- < x )
    \\
    &=
    \notag
    \int_{b_-}^{1} \dd x\, \frac{g(x)}{1-x}
    -
    \int_0^1 \dd x \frac{g(1)}{1-x}
    ,
    \\
    \int_{b_-}^{1} \dd b\,
    \le[\frac{1}{1-b}\ri]_+ g(b)
    &=
    \int_{b_-}^{1} \dd b\, \frac{g(b)}{1-b}
    -
    \int_0^1 \dd b \frac{g(1)}{1-b}
    .
\end{align}
These are equal.
\end{proof}

\end{example}


\remark{}{
    The above argument is a bit long-winded, but it is a good example of how to use the flavor of distributions to prove results involving integrals of plus-distributions.
    %
    The key point is that we can integrate the delta-function against a test function, and then integrate the plus-distribution against the same test function.
}

\remark{}{
    If we want to change the domain of integration (and we eventually will want to), we can use
    \begin{align}
        \int_{x_-}^1 \dd x\, \le[\frac{1}{1-x}\ri]_+ \delta(b - x)
        &=
        \int_0^1 \dd x\, \le[\frac{1}{1-x}\ri]_+ \delta(b - x) - \int_0^{x_-} \dd x\, \le[\frac{1}{1-x}\ri]_+ \delta(b - x)
        \\
        &=
        \notag
        \le[\frac{1}{1-b}\ri]_+ - \frac{1}{1-b} \Theta(b < x_-)
        =
        \le[\frac{1}{1-b}\ri]_+ \Theta(b > x_-)
        .
    \end{align}
}

Next, let us approach another subtlety.
%
What if, instead of using \(b\), we use \(-b\), or a more complicated function of \(b\)?
%
This is where some of the cumbersome notation introduced earlier can help us mitigate some of the areas where confusion can strike.
%
Based on the derivation above, we can write
\begin{align}
    \int_{0}^{1} \dd x\,\le[\frac{1}{1-x}\ri]_+ \delta(-b - x)
    &=
    \le[\frac{1}{1+b}\ri]_+^{-b\in(0,1)}
    =
    -\le[\frac{1}{1+b}\ri]_+^{b\in(0, -1)}
    =
    \le[\frac{1}{1+b}\ri]_+^{b\in(-1, 0)}
    .
\end{align}
In the first equality, we have used our earlier derivation, replacing \(b\) by \(-b\).
%
In the second equality, we have used the fact that an integral over \(-b\) can be related to minus one times an integral over \(b\) without flipping the bounds.
%
In the third equality, we have used that we may flip the bounds of integration of a one dimensional integral at the expense of an additional minus sign.

~\\
\begin{example}{}
    We now explore a related result which is useful in the study of physical applications:
    \begin{align}
        \int_{1-x}^{1} \dd y\,
        \le[\frac{1}{1-y}\ri]_+ \delta(b - x - y) w(x, y)
        &=
        \le[\frac{1}{1+x-b}\ri]^{x \in (b-1,b)}_+
        w(x, b-x)
        \Theta(x > b-1) \Theta(b > 1)
        \label{eq:mixed-bounds_1d_plus-distribution}
        \,,
    \end{align}
    where the additional weight \(w(x,y)\) is a function of \(x\) and \(y\) which is regular at \(y = 1\), and we require that the domain of integration for \(x\) is within \(\RR_+\).

\vspace{7pt}
\hrule
\vspace{7pt}

\begin{proof}
    We again perform a distributional proof, integrating both sides against \(\dd x f(x)\) over a region \(x \in \mc R = (x_-, x_+)\).
    %
    The factor of \(w(x,b-x)\) can be obtained by using the support of the delta function, so we concentrate on the remaining pieces of the expressions above.
    %
    On the left, we have
    \begin{align}
        \int_{\mc R} \dd x\, f(x)
        \int_{1-x}^{1} \dd y\,&
        \le[\frac{1}{1-y}\ri]_+ \delta(b - x - y)
        \\
        &=
        \notag
        \int_{\mc R} \dd x\,f(x)
        \le(
            \int_{1-x}^{1} \dd y\,
            \frac{1}{1-y}
            \delta(b - x - y)
            -
            \int_0^1 \dd y\,
            \frac{1}{1-y}
            \delta(b - x - 1)
        \ri)
        \\
        &=
        \notag
        \int_{\mc R} \dd x\,f(x)
        \le(
            \frac{1}{1+x-b}
            \Theta(1 > b - x > 1 - x)
            -
            \int_0^{1} \dd y\,
            \frac{1}{1-y}
            \delta(b - x - 1)
        \ri)
        \\
        &=
        \notag
        \int_{\mc R} \dd x\,\frac{f(x)}{1 + x - b}
        \Theta(x > b - 1)\Theta(b > 1)
        -
        \int_0^1 \dd y\,\frac{f(b-1)}{1-y}
        \Theta(b-1 \in \mc R)
        \\
        &=
        \notag
        \int_{\mc R} \dd x\,\frac{f(x)}{1 + x - b}
        \Theta(x > b - 1)\Theta(b > 1)
        -
        \int_{b-1}^b \dd x'\,\frac{f(b-1)}{1+x'-b}
        \Theta(b-1 \in \mc R)
        .
    \end{align}
    In the final line we have changed variables in the second integral from \(y\) to \(x' = b - y\), and we have flipped the bounds of integration to absorb the minus sign from \(\dd y = -\dd x'\).

    Note that if the domain of integration of \(x\) is within \(\RR_+\) -- or \(x_-, x_+ > 0\) then \(\Theta(b-1 \in \mc R) = \Theta(b > 1)\).
    %
    Therefore, if \(x_- > 0\), the left-hand side gives
    \begin{align}
        \int_{b-1}^b \dd x\,\frac{f(x) - f(b-1)}{1+x-b}
        \Theta(b > 1)
        +
        \int_b^{x_+} \dd x\,\frac{f(x)}{1+x-b}
        \Theta(b > 1)
        .
    \end{align}
    However, this is precisely the definition of the distribution on the right-hand side when integrated against \(\dd x f(x)\)!
\end{proof}
\end{example}



Next, let us consider the case where we have a two-dimensional integral over, say, \(x\) and \(y\) and plus functions in each variable.
%
Of course, if the integration over \(x\) is independent of \(y\), then we can perform two independent one-dimensional integrals, as in the previous section, and simply multiply the results together.
%
Instead, let us consider the case where the integration region is non-trivial:

\begin{exercise}

    Show that
    \begin{align}
        \int_{0}^{1} \dd x\,
        \int_{1-x}^{1} \dd y\,
        \le[\frac{1}{1-x}\ri]_+
        \le[\frac{1}{1-y}\ri]_+
        &=
        \int_{0}^{1} \dd x\,
        \le[\frac{1}{1-x}\ri]_+
        \log x
        \label{eq:simple_2d}
        \\
        &=
        \int_{0}^{1} \dd x\,
        \frac{\log x}{1-x}
        \notag
        \\
        &= \text{Li}_2(1-x)\Big|^1_0 = -\zeta(2)
        \label{eq:simple_2d_soln}
        ,
    \end{align}
    where we have used the definition of \(\text{Li}_n(x)\)\footnote{
        As a reminder, \(\text{Li}_n(x)\) is the polylogarithm function defined by
        \begin{align}
            \text{Li}_n(x) = \sum_{k=1}^\infty \frac{x^k}{k^n}
            ,
        \end{align}
        which can also be defined recursively for \(n \in \NN_+\) via:
        \begin{align}
            \text{Li}_1(x) &= \log(1-x)
            ,
            \\
            \text{Li}_{n+1}(x) &= \int_0^1 \dd y\, \frac{\text{Li}_n(y)}{y}
            .
        \end{align}
    } and that \(\text{Li}_n(1) = \zeta(n)\), \(\text{Li}_n(0) = 0\).
    %
    This example in particular helps to build intuition for the fixed-order phase space of \(e^+e^-\to\,\)hadrons, and appears in the computation of the \gls{eec} in \Prob{eec-dist}.
\end{exercise}


Now we can begin to explore what happens when we add some simple polynomial weights \(w(x,y)\) to the integrand -- such as the energy weights of the \gls{eec} or of \glspl{ewoc}.

\begin{example}
We have already shown the example with \(w(x,y) = 1\), so let us try
\begin{itemize}
    \item
        \(w(x,y) = x\);
    \item
        \(w(x,y) = y\);
    \item
        \(w(x,y) = x y\).
\end{itemize}

The first two should give the same result by symmetry of the integration region and plus-distribution pieces of the integrands under \(x \leftrightarrow y\).
%
The third example will be relevant for our double checking some of the results in our exploration of physical applications.

Let's evaluate the examples one-by-one:
\begin{itemize}
    \item
        \(w(x,y) = x\):
        \begin{align}
            \int_{0}^{1} \dd x\,
            x
            \int_{1-x}^{1} \dd y\,
            \le[\frac{1}{1-x}\ri]_+
            \le[\frac{1}{1-y}\ri]_+
            &=
            \int_{0}^{1} \dd x\,x\,
            \le[\frac{1}{1-x}\ri]_+
            \log(x)
            \\
            &=
            \int_{0}^{1} \dd x\,
            \frac{x \log x}{1-x}
            \notag
            \\
            &= 1 - \zeta(2)
            \notag
            ,
        \end{align}

    \item
        \(w(x,y) = y\):
        \begin{align}
            \int_{0}^{1} \dd x\,
            \int_{1-x}^{1} \dd y\,
            \le[\frac{1}{1-x}\ri]_+
            \le[\frac{1}{1-y}\ri]_+
            y
            &=
            \int_{0}^{1} \dd x\,
            \le[\frac{1}{1-x}\ri]_+
            \le(-x + \log(x)\ri)
            \\
            &=
            1 - \zeta(2)
            \notag
            .
            ~~~~~~~~
            {\Large \textbf{\textcolor{green!60!black}{\checkmark}}}
        \end{align}

    \item
        \(w(x,y) = x y\):
        \begin{align}
            \int_{0}^{1} \dd x\,
            \int_{1-x}^{1} \dd y\,
            \le[\frac{1}{1-x}\ri]_+
            \le[\frac{1}{1-y}\ri]_+
            x y
            &=
            \int_{0}^{1} \dd x\,x
            \le[\frac{1}{1-x}\ri]_+
            \le(-x + \log(x)\ri)
            \\
            &=
            H_2 + 1 - \zeta(2)
            \notag
            \\
            &=
            \frac{5}{2} - \zeta(2)
            \notag
            .
        \end{align}
\end{itemize}
\end{example}



In \Prob{two-plus_one-delta}, we explore the example with a delta function also in the integrand:
\begin{align}
    \int_{0}^{1} \dd x\,
    \int_{1-x}^{1} \dd y\,
    \le[\frac{1}{1-x}\ri]_+
    \le[\frac{1}{1-y}\ri]_+
    \delta(b - x - y)
    \label{eq:two-plus_one-delta}
    .
\end{align}
%
Though I find this example to be significantly harder than our previous examples, it is still rewarding to make sense of it.





% ===========================================================
\section*{A.II\phantom{IV.}Dimensional Regularization}
% ===========================================================
\setcounter{section}{2}
\addcontentsline{toc}{section}{A.II\phantom{IV.}Dimensional Regularization}

\begin{itemize}
    \item
        Definition, use

    \item
        See homework 3 from SUSY...

    \item
        Examples which connect easily to later splitting function and regularization/renormalization discussion
\end{itemize}


\begin{definitionbox}{Regularization}{regularization}
    \emph{\gls{regularization}} is a technique used in quantum field theory and other areas of physics to handle divergences in integrals, such as those that appear in loop calculations. The primary goal of regularization is to introduce a controlled way to deal with infinite quantities by modifying or "regularizing" the mathematical expressions that describe physical processes.

    \vspace{7pt}
    \hrule
    \vspace{7pt}

    In regularization, a small parameter or modification is introduced to make otherwise divergent integrals finite. Common techniques include introducing a cutoff scale, modifying the space-time dimensions, or using specific mathematical tools like the Dirac delta function. The key is that the regularization procedure should not alter the physical predictions once the divergences are removed.

\end{definitionbox}

\remark{}{
    Regularization is necessary in quantum field theory (QFT) to handle the infinite results of loop integrals that arise in perturbative calculations. It is a temporary step, as the divergences must be removed later during the renormalization process. The choice of regularization scheme can affect intermediate results but should not change the final, renormalized predictions.
}

\begin{definitionbox}{Dimensional Regularization}{dimreg}
    \emph{\gls{dimreg}} is a specific method of regularization that modifies the number of space-time dimensions to regulate divergences. Instead of cutting off the momentum integrals at some scale, dimensional regularization shifts the number of space-time dimensions from the physical value (typically 4 in quantum field theories) to \( d = 4 - 2\epsilon \), where \( \epsilon \) is a small parameter that ensures finiteness.

    \vspace{7pt}
    \hrule
    \vspace{7pt}

    In dimensional regularization, integrals that would normally be divergent in 4 dimensions are regularized by working in a non-integer dimension \( d \), and the result is then analytically continued to the physical dimension \( d = 4 \). This technique preserves gauge invariance and is particularly useful for dealing with ultraviolet divergences in quantum electrodynamics (QED) and quantum chromodynamics (QCD).
\end{definitionbox}

\remark{}{
    Dimensional regularization has several advantages, particularly in gauge theories, as it preserves important symmetries such as gauge invariance and supersymmetry. It also simplifies the renormalization process for certain types of divergences, making it a popular choice in quantum field theory and particle physics, especially in QCD calculations.
}

\remark{}{
    Dimensional regularization is closely connected to the renormalization process because it is typically used alongside renormalization schemes, such as minimal subtraction (\( \overline{\text{MS}} \)), to cancel out the divergences introduced by loop corrections in a way that is both mathematically consistent and physically meaningful.
}


% ===========================================================
\section*{A.III\phantom{V.}Review of the Mellin Transform}
% ===========================================================
\setcounter{section}{3}
\addcontentsline{toc}{section}{A.III\phantom{V.}Review of the Mellin Transform}


The Mellin transform was an important tool for us in capturing the behavior of the partonic cascade and associated correlations in \Secs{parton-shower}{eec}.
%
In particular, the Mellin transform is used to study the scaling properties of functions.
%
In \Sec{jets}, we touched upon this briefly in a footnote.
%
We said:

\vspace{7pt}
\hrule
\vspace{7pt}

homogenous monomials, such as \(x^{-\ell}\), have extremely simple scaling behavior:
%
as one scales \(x\) by a factor of \(a\), one obtains a deceptively simple relation \((a x)^{-\ell} = a^{-\ell} x^{-\ell}\);
%
if \(a < 1\), we have ``zoomed in'' to the behavior of the function near \(x = 0\).
%
We say that these simple monomials are \textit{eigenfunctions of the scaling} (or dilatation) \textit{operator}.
%
The scaling behavior of a more complicated function \(f(x)\) -- e.g. a concrete relationship between \(f(ax)\) and \(f(x)\) -- can then be captured explicitly if it is known how \(f(x)\) can be composed in terms of the simple building blocks \(x^{-\ell}\).
%
Luckily, \textit{the Mellin moments of a function \(f(x)\) precisely captures how \(f(x)\) is composed of the simple building blocks \(x^{-\ell}\), and therefore provides a complete and simple characterization of its scaling behavior.}

\vspace{7pt}
\hrule
\vspace{7pt}


We now present this intuition with more concrete examples and arguments.

\begin{exercise}
    Show \(\mathcal{M}[f(x^{-1})](\ell) = \mathcal{M}[f(x)](-\ell)\) and \(\mathcal{M}[f(a x)](\ell) = a^{-\ell} \mathcal{M}[f(x)](\ell)\), and connect these results to the relationship between the Mellin transform and the scaling behavior of functions discussed above.
    %
    Hopefully this exercise also impresses upon you the invariant properties of the Mellin measure that we are about to formalize below.
\end{exercise}


This intuition can be made even more precise by the use of the \vocab{Mellin inversion theorem}, which gives appropriate conditions under which the Mellin transform may be inverted,
\begin{proposition}{Mellin Inversion}{}
    If \(f(x)\) has a Mellin transform \(\phi(s)\) which is analytic in a strip \(a < \Re(s) < b\) of the complex-\(s\) plane and tends to zero uniformly as \(\Im s \to \pm \infty\) for any \(a < \Re(s) = c < b\), then we can recover \(f(x)\) from \(\phi(s)\) by
    \begin{align}
        f(x) = \mathcal{M}^{-1}[\phi(s)](x)
        =
        \frac{1}{2\pi i}
        \int_{c-i\infty}^{c+i \infty}
        \dd s
        \,
        x^{-s} \phi(s)
        \,.
    \end{align}
\end{proposition}
%
The Mellin inversion formula can then be used to prove the \vocab{Ramanujan master theorem}, which makes the intuition of the Mellin transform capturing the scaling behavior of functions very sharp:
\begin{proposition}{Ramanujan's Master Theorem}{}
    If a \(f(x)\) can be expressed in as a convergent sum of the form
    \begin{align}
        f(x) = \sum_{k = 0}^\infty (-1)^k a(k) \frac{x^k}{k!}
        \,,
    \end{align}
    in a large neighborhood of \(x = 0\), and \(a(k)\) is itself a well-behaved holomorphic function in the region \(\Re(k) \geq 0\), then the Mellin transform of \(f(x)\) is
    \begin{align}
        \mathcal{M}[f](s)
        =
        \Gamma(s) a(-s)
        \,.
    \end{align}

    In words, \textit{the Mellin transform of \(f(x)\), evaluated at \(s\) interpolates information about the pieces of \(f\) which behave like \(x^{-s}\)}.

    \vspace{7pt}
    \hrule
    \vspace{7pt}

    The terms ``large neighborhood'' and ``well-behaved'' require further definition outside of our scope, but a more precise definition can be found, for example, in \Reff{RamanujanMasterTheorem}.
\end{proposition}





\begin{exercise}
    \textbf{Warmup by Analogy: the Fourier Transform}

    In the Fourier transform, a central role is played by the \emph{translations}
    \begin{align}
        x \mapsto x + a
        .
    \end{align}
    The Fourier transform of a function \(f(x)\) divides the function \(f(x)\) into ``plane-wave'' components which are eigenstates of translation.

    The Fourier transform of a function \(f(x)\) is defined as
    \begin{align}
        \mc F[f(x)](k)
        \eqdelta
        \tilde f(k)
        &:=
        \int_{-\infty}^{\infty} \dd x \, e^{-ikx} f(x)
        .
    \end{align}

    \begin{enumerate}[label=\roman*)]
        \item
            What is the differential operator \(\mc T\) which implements an infinitesimal translation in \(x\)?
            %
            In particular, we are looking for \(\mc T\) such that:
            \begin{align}
                f(x) + \delta x \, \mc T f(x) = f(x+\delta x)
                .
            \end{align}

        \item
            Argue that the Fourier transform of \(f(x)\) can be divided into three conceptually distinct pieces:
            \begin{itemize}
                \item
                    Integration against a translation-invariant measure;

                \item
                    An eigenstate of the translation operator;

                \item
                    The function \(f(x)\) itself.
            \end{itemize}

        \item
            Using the invariance of the integration measure under translations, show that the Fourier tranform of \(f(x)\) after translation by \(a\) is simply related to the Fourier transform of \(f(x)\):
            \begin{align}
                \mc F[f(x+a)](k) = e^{ika} \tilde f(k)
                .
            \end{align}

        \item
            Show that the Fourier transform of \(\mc T f(x)\) is simply related to the Fourier transform of \(f(x)\).
    \end{enumerate}
\end{exercise}

\begin{exercise}
    \textbf{Finally: the Mellin Transform}

    The Mellin transform is similar to the Fourier transform, except that it is now \emph{dilations} which play a central role:
    \begin{align}
        x \mapsto \lambda x
        .
    \end{align}
    The Mellin transform of a function \(f(x)\) divides the function \(f(x)\) into analogous components which are eigenstates of dilation.

    \begin{enumerate}[label=\roman*)]
        \item
            What is the differential operator \(\mc D\) which implements an infinitesimal \vocab{dilation} in \(x\)?
            %
            In particular, we are looking for \(\mc D\) such that:
            \begin{align}
                f(x) + \delta \lambda \, \mc D f(x)
                =
                f\le(\le(1 + \delta \lambda\ri)x\ri)
                .
            \end{align}

        \item
            Argue that the Mellin transform of \(f(x)\) can be divided into three conceptually distinct pieces:
            \begin{itemize}
                \item
                    Integration against a dilation-invariant measure;

                \item
                    An eigenstate of the dilation operator;

                \item
                    The function \(f(x)\) itself.
            \end{itemize}

        \item
            Using the invariance of the integration measure under dilations, show that the Mellin tranform of \(f(x)\) after dilation by \(\lambda\) is simply related to the Mellin transform of \(f(x)\):
            \begin{align}
                \mc M[f(\lambda x)](s) = \lambda^{-s} \hat f(s)
                .
            \end{align}

        \item
            Without performing a calculation, how do you expect the Mellin transform of \(\mathcal{D} f(x))\) to be related to the Mellin transform of \(f(x)\)?
            %
            Why?
            %
            Now, calculate \(\mathcal{M}\le[\mathcal{D} f(x)\ri]\) and compare it the result to your intuitive expectation.
    \end{enumerate}
\end{exercise}



An important mathematical piece in our analysis of the splitting of trees and the sharing of momentum in the partonic cascade was the \textit{Mellin convolution}.
%
The Mellin convolution is defined by the following formal relation:
\begin{align}
    \label{eq:convolution-property}
    \mathcal{M}[f \mellinconvolution g](s)
    =
    \mathcal{M}[f](s) \, \mathcal{M}[g](s)
    \,.
\end{align}
In other words, a \vocab{Mellin convolution} of two functions \(f\) and \(g\) is a bi-linear map of the functions whose Mellin transform is the product of the individual Mellin transforms of \(f\) and \(g\).
%
Since it is a bi-linear map of the two functions, it seems natural to express it as an integral.
%
In particular,
\begin{proposition}{Mellin Convolution}{mellin-convolution-app}
    The \vocab{Mellin convolution}
    \begin{align}
        (f \mellinconvolution g)(x)
        =
        \int_0^\infty \frac{\dd y}{y}\, f(y) g(x/y)
        \,,
    \end{align}
    satisfies the natural convolution property of \Eq{convolution-property}.
\end{proposition}
%
We have seen this convolution in our exploration of the scaling behavior of parton showers in \Sec{parton-shower} (and thus in the behavior of the resummed \gls{eec} in \Sec{eec}), and even in our exploration of parton-to-hadron fragmentation in \Prob{p2h-fragmentation}.
%
The proof of this result is left to \Prob{mellinconvolution}





% Problems for Appendix
% ===========================================================
\begin{appproblems}
% ===========================================================
    \makeprob{The Cauchy Principle Value}{principle-value}{
        Provide a formal argument that
        \begin{align}
            \frac{\dd}{\dd x} \ln\le(\abs{x}\ri)
            =
            \text{PV}\le(\frac{1}{x} \ri)
            \,,
        \end{align}
        where the right-hand-side is the \vocab{Cauchy Principle Value}, a distribution defined by
        \begin{align}
            \int_{-\infty}^{\infty} \dd x
            \,\,
            \text{PV}\le(\frac{1}{x} \ri)
            \,
            \phi(x)
            =
            \int_0^\infty
            \,
            \frac{\phi(x) - \phi(-x)}{x}
            \,
            \dd x
            \,.
        \end{align}
    }

    \makeprob{The Sokhatski-Plemelj Formula}{sokhatski-plemelj}{
        Prove the \vocab{Sokhotski-Plemelj formula},
        \begin{align}
            \lim_{\epsilon\to0}\frac{1}{x\pm i\epsilon}
            =
            \text{PV}\frac{1}{x}
            \mp
            i\pi \delta(x)
            ,
        \end{align}
        by analyzing the behavior of \(\log(z)\) in the complex plane (on the principal sheet from \(-\pi < \arg(z) < \pi\)).
    }

    \makeprob{A Useful Plus-Function Identity}{plus-identity}{
        Prove that
        \begin{align}
            x^{-1+\epsilon}
            =
            \frac{1}{\epsilon} \delta(x)
            +
            \sum_{n=0}^\infty
            \frac{\epsilon^n}{n!}
            \le[\frac{\ln^n(x)}{x}\ri]_+^{(0,1)}
            \,.
        \end{align}
        What happens to this expression if the bounds on the \glslink{plus-fn}{plus-functions} are changed?

        (from Chapter 32 of \underline{Quantum Field Theory and the Standard Model})
    }

    \makeprob{Two Plus, One Delta}{two-plus_one-delta}{
        Show that
        \begin{equation}
            \int_{0}^{1} \dd x\,
            \int_{1-x}^{1} \dd y\,
            \le[\frac{1}{1-x}\ri]_+
            \le[\frac{1}{1-y}\ri]_+
            \delta(b - x - y)
            =
            2 \le[ \frac{\log(2 - b)}{2 - b} \ri]_+^{b\in(1,2)}
            -
            \delta(b - 2) \zeta(2)
            .
       \end{equation}
    }

    \makeprob{Practice with Dimensional Regularization}{dimreg-practice}{
        \sam{Steal from SUSY?}
    }



    \makeprob{Mellin Convolution Theorem}{mellinconvolution}{
        Prove the Mellin Convolution Theorem of Proposition~\ref{prop:mellin-convolution-app}.
    }

    \makeprob{Mellin Convolution Theorem II}{mellinconvolution2}{
        There is another, related convolution in the context of Mellin transforms.
        %
        Consider the new convolution
        \begin{align}
            (f \circ_{\mc M} g)(x)
            =
            \int_0^\infty\,\dd\xi f(x\,\xi) g(\xi)
            \,.
        \end{align}
        Show that the Mellin transform of this convolution is
        \begin{align}
            \mathcal{M}[f \circ_{\mc M} g](s)
            \,
            =
            \,
            \mathcal{M}[f](s) \, \mathcal{M}[g](1-s)
            \,.
        \end{align}
    }
\end{appproblems}
